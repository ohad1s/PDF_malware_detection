from sklearn.feature_extraction.text import  HashingVectorizer
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import HistGradientBoostingClassifier




to_extract=["obj"	,"endobj",	"stream"	,"endstream",
            "xref",	"trailer",	"startxref"	,"pageno",	"encrypt"	,"ObjStm",
            "JS"	,"Javascript"	,"AA"	,"OpenAction",	"Acroform"	,"JBIG2Decode"
    ,"RichMedia"	,"launch",	"EmbeddedFile"	,"XFA",	"Colors",
           "pdfsize",   "metadata size",   "pages",   "xref Length",   "title characters" ,   "isEncrypted" , "embedded files"
           , "images" ]

def extract_num():
    for col in to_extract:
        df[col] = df[col].astype(str).str.extract('(\d+)')


df = pd.read_csv("../dataSet/PDFMalware2022.csv")

# Convert the file_name feature into numerical representation using Tf-Idf
df['Class'] = df['Class'].map({'malware': 1, 'benign': 0})
df['text'] = df['text'].map({'Yes': 1, 'No': 0,'unclear':-1})
df.drop("header", axis=1, inplace=True)
vectorizer = TfidfVectorizer()
train_file_name = vectorizer.fit_transform(df["Fine name"])
df["Fine name"]=train_file_name.toarray()
cols_with_nan = df.columns[df.isnull().any()].tolist()
# Print the column names
print("Columns containing NaN values:", cols_with_nan)


# Split the dataframe into training and testing datasets

extract_num()
df.fillna(df.mean(), inplace=True)
cols_with_nan = df.columns[df.isnull().any()].tolist()
# Print the column names
print("Columns containing NaN values:", cols_with_nan)
X = df
y = df['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
# Initialize StandardScaler
# scaler = StandardScaler()
#
# # Fit the scaler to the training data
# scaler.fit(X_train)
#
# # Transform the training and testing data
# X_train = scaler.transform(X_train)
# X_test = scaler.transform(X_test)

# Train a Random Forest Classifier
classifier = HistGradientBoostingClassifier()

# Fit the model on the training set
classifier.fit(X_train, y_train)

# Evaluate the model on the test set
y_pred = classifier.predict(X_test)

# Calculate the accuracy of the model
accuracy = classifier.score(X_test, y_test)
print("Accuracy: ", accuracy)

# df['Class'] = df['Class'].map({'malware': 1, 'benign': 0})
# df['text'] = df['text'].map({'Yes': 1, 'No': 0,'unclear':-1})
# df.drop('header', axis=1, inplace=True)
# COMPLEX_HEADERS=["Fine name"]
# for column in df.columns[df.isna().any()].tolist():
#     df.drop(column, axis=1, inplace=True)
#
# def vectorize_df(df):
#     le = LabelEncoder()
#     h_vec = HashingVectorizer(n_features=4)
#
#     # Run HashingVectorizer on the chosen features
#     for column in COMPLEX_HEADERS:
#         newHVec = h_vec.fit_transform(df[column])
#         df[column] = newHVec.todense()
#
#     return df
#
#
# # X = df.drop("Class")
# y = df['Class']
# df.drop('Class', axis=1, inplace=True)
# df= vectorize_df(df)
# X=df
#
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
#
#
#
#
# # Split the dataframe into training and testing datasets
# train, test = train_test_split(df, test_size=0.2, random_state=42)
#
# # Convert the file_name feature into numerical representation using Tf-Idf
#
# # Train a Random Forest Classifier
# classifier = RandomForestClassifier()
# classifier.fit(X_train, y_train)
# y_pred = classifier.predict(X_test)
# # Evaluate the model on the test data
# accuracy = classifier.score(X_test, y_test)
# print("Accuracy: ", accuracy)
